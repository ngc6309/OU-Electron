{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting models to data \n",
    "\n",
    "A common scientific task is to formulate a mathematical model and 'fit' that model to experimental data. One of the simplest and most used ways of doing this is called 'Linear least squares regression'. It is what is usually meant when terms like  \"regression\", \"linear regression\" or \"least squares\" are used.\n",
    "\n",
    "In the least squares method, we have a mathematical model, defined with a number of parameters, and some data points. As an example, a simple model (straight line) would be \"y=mx + c\" which has 2 parameters 'm' (the slope or gradienat of the line) and 'c' (the intercept. \n",
    "\n",
    "The regression process is one of optmising the 'fit' of the line to the data by establishing the 'best' values for the parameters that minimises the sum of the squared distances, or deviations, between the data points and the model.\n",
    "\n",
    "In this notebook, we'll explore how to do this using some of the fitting tools and functions available with Python.\n",
    "\n",
    "We'll do all the imports and other housekeeping we need here before moving on. You'll note that we'll be using both Matplotlib and Bokeh as display packages - just for variety, you could use either.\n",
    "\n",
    "We also need to import packages from sciPy. (**.stats.lingress()**, **.optimize.curve_fit()**, and **.odr()**) but, unusually, we'll import these as we need them to emphasise their usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "# These 2 lines just allow 'pretty' printing of pandas stuff - non-essential\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Set the size of subsequent plots\n",
    "plt.rcParams['figure.figsize']=[10,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. The data\n",
    "\n",
    "For the purposes of the next few sections of this notebook, a file with data is provided (\"line_data.csv\" - later on you'll also use \"gaus_rand.csv\"). \n",
    "\n",
    "This is designed to represent typical experimental data that might be modeled with a straight line. There are 4 columns - 'xdat' and 'ydat', which are the x and y values, and 'xerr' and 'yerr' which are the estimated uncertainties or errors on the x and y data points.\n",
    "\n",
    "First, we'll read in the data and make a rough plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('line_data.csv')\n",
    "\n",
    "# What does it look like? - just for info\n",
    "df.head()\n",
    "\n",
    "# Set up x and y - not strictly necessary, but convenient\n",
    "x=df['xdat']\n",
    "y=df['ydat']\n",
    "y0=y\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Simple regression - scipy linregress()\n",
    "\n",
    "So, that looks like a straight line might fit - what's the bet fit we can obtain?\n",
    "\n",
    "One of the simplest ways is to use a sciPy function: **scipy.stats.linregress()**, which is very easy to use.\n",
    "\n",
    "This gives us a least squares fit, returning the slope, intercept, rvalue, pvalue and a standard error. The rvalue squared tells you something about the 'goodness' of the fit - the closer to 1 the better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "m,c,r_val,p_val,sterr = linregress(x,y)\n",
    "\n",
    "print(f'Gradient is {m:.2f}, Intercept is {c:.2f} and standard error is {sterr:.2f}')\n",
    "\n",
    "# Plot the line on to the data:\n",
    "plt.scatter(x,y)\n",
    "xlin = np.linspace(2.5,10.5,50)\n",
    "plt.plot(xlin,(m*xlin+c), color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting more statistical information\n",
    "\n",
    "This is fine for many purposes and is pretty much what you get wen you fit a line to data in a speadsheet such as Microsoft Excel.\n",
    "\n",
    "Often though, you need to know something more about how accurate the optimised parameters are. For this we need to use another sciPy function - scipy.optimize.curve_fit().\n",
    "\n",
    "This is a much more general function that linregress() and allows you to define a model function that you want to fit - you are not constrained to a straight line. As it happens, in this case, we do actually want a straight line but we'll need to define it - in a specific manner using a function.\n",
    "\n",
    "It returns 2 objects, one containing the optimised parameters to the model and a \"covariance matrix\" that contains quite a lot of statistical data. We can use this statistical data to get esimates of how accurate the returned optimised parameters are.\n",
    "\n",
    "The model function you define must  take the independent variable as the first argument and the parameters to fit as separate remaining arguments.\n",
    "\n",
    "As usual it's probably easiest to present this as an example - using the data we've already got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define a simple, straight line model, accepting an x value or 1D array and using \n",
    "# gradient and intercept parameters. \n",
    "#\n",
    "# As you can see if you passed this an x value it would calculate the corresponding y.\n",
    "# If you pass it an numpy array or pandas series it will return a corresponding array\n",
    "# of y values.\n",
    "def stLineFit(x, m, c):\n",
    "    return (m*x + c)\n",
    "\n",
    "# Call the fitting function - with, note,  2 retun values. The variables 'popt' and 'pcov' \n",
    "# are called this by convention but any 2 names would do.\n",
    "popt, pcov = curve_fit(stLineFit, x, y)\n",
    "# Calculate the 'accuracy' of the returned parameters\n",
    "perr = np.sqrt(np.diag(pcov)) # error values are on the covariance matrix diagonal\n",
    "\n",
    "# Now we can print out the optimised fit parameters and 1-sigma estimates\n",
    "print('fit parameter 1-sigma error')\n",
    "print('***************************************************')\n",
    "print (f'm = {popt[0]:.2f} +- {perr[0]:.2f}')\n",
    "print (f'c = {popt[1]:.2f} +- {perr[1]:.2f}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Now plot the data and add the optimised line. WE could do this in exactly the same way as we\n",
    "# did for the lingress() example, or, use our stLineFit() function:\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,stLineFit(x,m,c), color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What if we have estimated uncertainties on the y axis?\n",
    "\n",
    "Experimantal data often has (in fact, ought to have) estimates of how uncertain the measurement is - it has associated errors. \n",
    "\n",
    "Simple functions like linregress() treat all data points as equal. However, it's reasonable to suppose that data points with small errors should be 'weighted' much more heavily that those with large estimated errors. Luckily there are algorithms that do just that.\n",
    "\n",
    "Scipy.optimize.curve_fit() allows us to utilise the error estimates in y that we have in the data. The sciPy method takes the model function you define along with x and y as well as y errors. (the absolute_sigma=True tells the function we are passing it absolute errors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# First get some y error from the DataFrame we've already read in\n",
    "yerror = df['yerr']\n",
    "\n",
    "# Plot it - with error bars\n",
    "plt.errorbar(x, y, yerr=yerror, capsize=2, fmt='o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again, define a straight line model function.\n",
    "def stLineFit(x, m, c):\n",
    "    return (m*x + c)\n",
    "\n",
    "# Call the fitting function - with, note,  2 retun values. The variables 'popt' and 'pcov' \n",
    "# are called this by convention but any 2 names would do.\n",
    "popt, pcov = curve_fit(stLineFit, x, y, sigma=yerror, absolute_sigma=True)\n",
    "# Calculate the 'accuracy' of the returned parameters\n",
    "perr = np.sqrt(np.diag(pcov)) # error values are on the covariance matrix diagonal\n",
    "\n",
    "#print fit parameters and 1-sigma estimates\n",
    "print('fit parameter 1-sigma error')\n",
    "print('***************************************************')\n",
    "print (f'm = {popt[0]:.2f} +- {perr[0]:.2f}')\n",
    "print (f'c = {popt[1]:.2f} +- {perr[1]:.2f}')\n",
    "print('***************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confidence bounds or limits\n",
    "\n",
    "You could now go on to just plot this new estimated line as before.\n",
    "\n",
    "However, as you can see, we have more information about uncertainties in the gradient and the intercept and we could use this information to show a set of 'confidence' bound around it.\n",
    "\n",
    "First calculate these bound lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare confidence level line limits\n",
    "nstd = 1.0 # to draw 1 sigma interval\n",
    "# Note, remember these are numpy arrays\n",
    "popt_up = popt + nstd*perr\n",
    "popt_dw = popt - nstd*perr\n",
    "\n",
    "# Get the fitted line\n",
    "fit = stLineFit(x, *popt)\n",
    "# Add and subtract error values\n",
    "fit_up = stLineFit(x, *popt_up)\n",
    "fit_dw = stLineFit(x, *popt_dw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "# Set plot parameters\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['font.size']= 2\n",
    "plt.errorbar(x, y, yerr=yerror, capsize=5, fmt='none', ecolor='k', label='Errors')\n",
    "plt.xlabel('x', fontsize=18)\n",
    "plt.ylabel('y', fontsize=18)\n",
    "plt.title('x Vs y with best fit line and 1 sigma confidence', fontsize=18)\n",
    "plt.plot(x, fit, 'r', lw=2, label='Best fit line')\n",
    "plt.plot(x, y0, 'o', lw=2, label='Data points')\n",
    "ax.fill_between(x, fit_up, fit_dw, alpha=.25, label='1-sigma interval')\n",
    "plt.legend(loc='upper left',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. X and Y errors\n",
    "\n",
    "You'll note that so far we've ignored the errors in x. Linear regression tries to minimise the sum of the squares of the 'error' an in 'usual' use (as in curve_fit), the error is only considered in the 'y' value residual measured to the fitted line. In other words we are mimimising the residuals obtained by measuring a **vertical** distance from the data point to the model line. \n",
    "\n",
    "This is fine unless we have errors in both y AND x. In this case it is better to use the **orthoganal** distance from the data point to the fitted line - Orthogonal Distance Regression (ODR). \n",
    "\n",
    "Luckily there is a function for that. So, here we use it - the scipy **.odr()** function. Do note that we need to define the model function in a different way!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import odr\n",
    "\n",
    "# Just a simple function to return a straight line for use in ODR.\n",
    "# BUT, note that it is defined in a slightly different way to 'curve_fit()'\n",
    "# You pass it a list/tuple of parameters and 'x' comes at the end - not first\n",
    "def stLine(p,x):\n",
    "    # 'p' is alist containing 'm' and 'c'\n",
    "    m,c = p\n",
    "    return m * x  + c\n",
    "\n",
    "# We also need the x errors - so read them in\n",
    "xerror=df['xerr']\n",
    "\n",
    "# Need to use scipy 'odr' model for fitting. \n",
    "model = odr.Model(stLine)\n",
    "# Form an odr 'RealData' object\n",
    "rdata = odr.RealData(x,y,sx=xerror,sy=yerror)\n",
    "# Now set up the ODR, \n",
    "# We need an initial 'guess' of m and c - beta0 \n",
    "# We could 'hard wire' this but as we now we are looking at a straight line,\n",
    "# we'll use scipy.stats.linregress() to get an estimate.\n",
    "# We need the first 2 elements returned which are slope and intercept (m and c)\n",
    "init_guess = linregress(x,y)[0:2]\n",
    "odr=odr.ODR(rdata, model, beta0=init_guess )\n",
    "\n",
    "# Run it and get the results\n",
    "result_outputs = odr.run()\n",
    "\n",
    "# Extract the data we need\n",
    "popt = result_outputs.beta\n",
    "perr = result_outputs.sd_beta\n",
    "\n",
    "#print fit parameters and 1-sigma estimates\n",
    "print('fit parameter 1-sigma error')\n",
    "print('***************************************************')\n",
    "print (f'm = {popt[0]:.2f} +- {perr[0]:.2f}')\n",
    "print (f'c = {popt[1]:.2f} +- {perr[1]:.2f}')\n",
    "print('***************************************************')\n",
    "\n",
    "# Now plot the data and fitted line:\n",
    "#plt.scatter(x,y)\n",
    "#plt.errorbar(x, y, yerr=yerror, xerr=xerror, hold=True, ecolor='k', fmt='none')\n",
    "plt.errorbar(x, y, yerr=yerror, xerr=xerror, fmt='o', ecolor='k', label='Errors')\n",
    "plt.plot(x, stLine((popt[0], popt[1]),x), color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using other models\n",
    "\n",
    "the scipy 'curve_fit()' and 'odr()' functions allow you to define pretty much any model you want to fit your data.\n",
    "\n",
    "As an example - and this will definitely prove useful later, a 'Gaussian' can be defined using 3 parameters:\n",
    "\n",
    "$$a*np.exp(-(x-x0)**2/(2*sigma**2))$$\n",
    "\n",
    "Where **a** is its amplitude, **x0** it's position on the x axis, and **sigma** a measure of it's width.\n",
    "\n",
    "Let's have a look at  some noisy data that might typically come from, say, a thermally broadend spectral line. The physics of this indicate that a Gaussian should be a good model to use.\n",
    "\n",
    "There is some demo data in the file 'gaus_rand.csv'. This has 2 columns of x and y values with column headers 'x' and 'y'. For your information, the data was generated using a=20, x0=10, sigma=1 with a random 'y' noise value added.\n",
    "\n",
    "So, let's read it in, display it, do a fit, get the optimised parameters and display it. Here we'll, arbitarily, use Bokeh - Matplotlib would work just as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "# define a Gaussian model\n",
    "def gauss(x, a, x0, sigma):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "# Read the data and do a quick-and-dirty plot\n",
    "df = pd.read_csv('gaus_rand.csv')\n",
    "df.plot('x', 'y', kind='scatter')\n",
    "\n",
    "# Do the fit\n",
    "popt, pcov = curve_fit(gauss,df['x'],df['y'],p0=[20,10,2])\n",
    "\n",
    "# What are the optimised parameters?\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print ('a = ' + str(popt[0]))\n",
    "print ('x0 = ' + str(popt[1]))\n",
    "print ('sigma = ' + str(popt[2]))\n",
    "print('***************************************************')\n",
    "\n",
    "# Now we can also get the confidence interval (1-sigma in this case)\n",
    "perr = np.sqrt(np.diag(pcov)) # error values are on the covariance matrix diagonal\n",
    "\n",
    "#print fit parameters and 1-sigma estimates\n",
    "print()\n",
    "print('fit parameter 1-sigma error')\n",
    "print('***************************************************')\n",
    "print ('a = ' + str(popt[0])+' +- '+str(perr[0]))\n",
    "print ('x0 = ' + str(popt[1])+' +- '+str(perr[1]))\n",
    "print ('sigma = ' + str(popt[2])+' +- '+str(perr[2]))\n",
    "print('***************************************************')\n",
    "\n",
    "# Plot the data with the optimised curve:\n",
    "p1 = figure(title = \"Fitting a Gaussian to data\", \n",
    "          x_axis_label='x', \n",
    "          y_axis_label='y')\n",
    "p1.scatter(df['x'],df['y'], legend='Data')\n",
    "p1.line(df['x'],gauss(df['x'],popt[0],popt[1],popt[2]), \n",
    "        color='red', \n",
    "        line_dash=\"dashed\", \n",
    "        legend='Optimised curve')\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy=\"hide\"\n",
    "show(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Although we have not gone into it here, .curve_fit() allows you to set 'bounds' for the optimised parameters. For example you might know that, due to constraints imposed by physical processes, there willl be a maximum FWHM/sigma for any Gaussian fitted, or you might want to ignore Gaussians that are too small in height, and so on. The official documentation is at https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fitting multiple peaks\n",
    "\n",
    "However, what happens if we have more than one peak in the data?\n",
    "\n",
    "We've provided a synthesised data set (twinPeaks.csv) that contains a pair of obvious peaks - you might get something like this when observing gaseous nebula using a narrow band OIII filter with a spectrometer. Don't forget this needs to be in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "output_notebook()\n",
    "\n",
    "# These 2 lines just allow 'pretty' printing of pandas stuff - non-essential\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Read the data and do a quick-and-dirty plot\n",
    "df = pd.read_csv('twinPeaks.csv')\n",
    "df.head()\n",
    "df.plot('wavelength', 'intensity', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we have two peaks that need fitting here - one (call it peak A) around channel 5050 and one (peak B)around channel 5085. We can also see that the first peak has a height of around 900 and a FWHM of around 10, the second a height of about 200 and a FWHM of 10.\n",
    "\n",
    "There are a number of ways to deal with this and we'll look at 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Isolate the specific area of interest.\n",
    "\n",
    "We could just isolate the area of interest by using slices of the overall data and repeat. Here we'll prompt the user for 3 bits of information:\n",
    "\n",
    "1. An estimate of the 'x' position of the peak of interest.\n",
    "2. An estimate of the height.\n",
    "3. An estimate of the FWHM - this will allow us to isolate a sloce of data and also give us a begining sigma.\n",
    "\n",
    "Note a couple of things here:\n",
    "\n",
    "* There is a generally accepted relationship for a Gaussian where FWHM is approximately 2.35482 * sigma.\n",
    "* Watch out for data where the x axis values don't start at 0. When you need to slice the data, you would naturally tend to use .iloc (see UsingPandas). BUT for data where the data does NOT start at 0, the data index and actual data will be 'out of step'. Get around this by indexing the DataFrame on the 'x' values and using .loc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Gaussian model\n",
    "def gauss(x, a, x0, sigma):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "# Having inspected the spectrum, get some fit estimates\n",
    "x0est = int(input('Estimated peak position? '))\n",
    "aest = float(input('Estimated peak height? '))\n",
    "FWHMest = float(input('Estimated peak FWHM? '))\n",
    "\n",
    "\n",
    "# Calculate an estimates sigma from the accepted relationship FWHM approx = 2.35 * sigma\n",
    "sigmaest = FWHMest/2.35\n",
    "\n",
    "# We need to re-index the DataFrame on the channel data \n",
    "# This is necessary so that we can 'slice' the data based on the displayed wavelength rather\n",
    "# than the actual data index.\n",
    "df.set_index('wavelength', inplace=True, drop=False)\n",
    "\n",
    "# Get area of interest \n",
    "x = df['wavelength'].loc[x0est-FWHMest : x0est+FWHMest]\n",
    "y = df['intensity'].loc[x0est-FWHMest : x0est+FWHMest]\n",
    "\n",
    "# do the fit\n",
    "popt, pcov = curve_fit(gauss,x,y,p0=[aest,x0est,sigmaest])\n",
    "\n",
    "# What are the optimised parameters?\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print ('a = ' + str(popt[0]))\n",
    "print ('x0 = ' + str(popt[1]))\n",
    "print ('sigma = ' + str(popt[2]))\n",
    "print('***************************************************')\n",
    "\n",
    "# Plot to check it (Matplotlib): \n",
    "# plt.plot(df['wavelength'],df['intensity'], label='Data', color='lightgrey', linewidth=5)\n",
    "# plt.plot(df['wavelength'],gauss(df['wavelength'],popt[0],popt[1],popt[2]), 'r--')\n",
    "\n",
    "# Plot the data with the optimised curve (Bokeh):\n",
    "p1 = figure(title = \"Fitting a Gaussian to multiple peaks\", \n",
    "          x_axis_label='Wavelength (Angstroms)', \n",
    "          y_axis_label='Intensity')\n",
    "p1.scatter(df['wavelength'],df['intensity'], legend='Data')\n",
    "p1.line(df['wavelength'],gauss(df['wavelength'],popt[0],popt[1],popt[2]), \n",
    "        color='red', \n",
    "        line_dash=\"dashed\", \n",
    "        legend='Optimised curve')\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy=\"hide\"\n",
    "show(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You could now repeat for peak B - either by re-running the code or putting the whole thing in a loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7.2 Create a more complex 'gauss' function\n",
    "\n",
    "We can also approach the problem by using a 'gauss' function that actually assumes we need 2 gaussians for a curve_fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a 2 Gaussian model\n",
    "def gauss2(x, a1, x10, sigma1, a2, x20, sigma2):\n",
    "    return a1*np.exp(-(x-x10)**2/(2*sigma1**2)) + a2*np.exp(-(x-x20)**2/(2*sigma2**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As before we could prompt the user for the initial estimates. Here, however, for brevity we'll hard-code them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x10est = 5050\n",
    "x20est = 5080\n",
    "a1est = 900\n",
    "a2est = 200\n",
    "# We won't be using FWHM here so we'll just use sigma estimates - once again for brevity\n",
    "sigma1est = 10/2.35\n",
    "sigma2est = 10/2.35\n",
    "\n",
    "# We'll stick these into a list for ease of handling\n",
    "p0 = [a1est, x10est, sigma1est, a2est, x20est, sigma2est]\n",
    "\n",
    "# x and y are:\n",
    "x = df['wavelength']\n",
    "y = df['intensity']\n",
    "\n",
    "# do the fit\n",
    "popt, pcov = curve_fit(gauss2,x,y,p0)\n",
    "\n",
    "# What are the optimised parameters?\n",
    "print('fit parameters')\n",
    "print('***************************************************')\n",
    "print ('a1 = ' + str(popt[0]))\n",
    "print ('x10 = ' + str(popt[1]))\n",
    "print ('sigma1 = ' + str(popt[2]))\n",
    "print ('a2 = ' + str(popt[3]))\n",
    "print ('x20 = ' + str(popt[4]))\n",
    "print ('sigma2 = ' + str(popt[5]))\n",
    "print('***************************************************')\n",
    "print(f'Peaks are at wavelegths of {popt[1]:.0f} and {popt[4]:.0f} Angstroms')\n",
    "print('***************************************************')\n",
    "\n",
    "# Plot it (Matplotlib)\n",
    "# plt.plot(df['wavelength'],df['intensity'], label='Data', color='lightgrey', linewidth=5)\n",
    "# plt.plot(df['wavelength'],gauss2(df['wavelength'],popt[0],popt[1],popt[2],\n",
    "#                                popt[3], popt[4], popt[5]), 'r--')\n",
    "\n",
    "# Plot the data with the optimised curve (Bokeh):\n",
    "p1 = figure(title = \"Fitting a Gaussian to multiple peaks\", \n",
    "          x_axis_label='Wavelength (Angstroms)', \n",
    "          y_axis_label='Intensity')\n",
    "p1.scatter(df['wavelength'],df['intensity'], legend='Data')\n",
    "p1.line(df['wavelength'],gauss2(df['wavelength'],popt[0],popt[1],popt[2], \\\n",
    "                              popt[3], popt[4], popt[5]), \n",
    "        color='red', \n",
    "        line_dash=\"dashed\", \n",
    "        legend='Optimised curve')\n",
    "p1.legend.location = \"top_left\"\n",
    "p1.legend.click_policy=\"hide\"\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
